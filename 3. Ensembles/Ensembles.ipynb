{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gU7AYPXMmA"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that.\n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO-jJrtNXMmH"
      },
      "outputs": [],
      "source": [
        "NAME = \"Βασίλειος Παπαστέργιος\"\n",
        "AEM = \"3651\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh0EE7BJXMmJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VpnGyWXMmK"
      },
      "source": [
        "# Assignment 3 - Ensemble Methods #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dQ9XoGQXMmK"
      },
      "source": [
        "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvHYIhS-XMmL"
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joKwpih2XMmM"
      },
      "source": [
        "## Download the Dataset ##\n",
        "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file.\n",
        "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJdwPr0bXMmM",
        "outputId": "670cd01a-d7ec-4854-bb3b-a596eecebee3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test_set_noclass.csv', <http.client.HTTPMessage at 0x7f11ec90c820>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import urllib.request\n",
        "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
        "filename_train = 'train_set.csv'\n",
        "urllib.request.urlretrieve(url_train, filename_train)\n",
        "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
        "filename_test = 'test_set_noclass.csv'\n",
        "urllib.request.urlretrieve(url_test, filename_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0OVtYr7XMmN"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the data\n",
        "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
        "train_set.head()\n",
        "X = train_set.drop(columns=['CLASS'])\n",
        "y = train_set['CLASS'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XK751YSecqQ",
        "outputId": "e9222770-7a28-4ace-8a5c-29dce4e56f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQH40Vb5fvx2"
      },
      "source": [
        "The following code will reduce the number of instances, dealing with the small imbalance of the dataset, as well as reducing the size of the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIgD6Nmkeaxv",
        "outputId": "a54e85b3-abdf-4124-9b81-576e0d6340fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({0: 1687, 1: 1687})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import NeighbourhoodCleaningRule, RandomUnderSampler\n",
        "\n",
        "ncr = NeighbourhoodCleaningRule()\n",
        "X_res, y_res = ncr.fit_resample(X, y)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_res, y_res = rus.fit_resample(X_res, y_res)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "X = X_res\n",
        "y = y_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxOGHSmqXMmO"
      },
      "source": [
        "## 1.0 Testing different ensemble methods ##\n",
        "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **5-fold cross validation** for your tests and report the average f-measure weighted and balanced accuracy of your models. You can use [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) and select both metrics to be measured during the evaluation.\n",
        "\n",
        "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww_u4OlrXMmO"
      },
      "source": [
        "### 1.1 Voting ###\n",
        "Create a voting classifier which uses two **simple** estimators/classifiers. Test both soft and hard voting and report the results. Consider as simple estimators the following:\n",
        "\n",
        "\n",
        "*   Decision Trees\n",
        "*   Linear Models\n",
        "*   KNN Models  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xKWBVWVz3yV",
        "outputId": "37fbc8aa-7f38-4d4b-c010-6a70d681e564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
            "                             ('decision_tree',\n",
            "                              LogisticRegression(random_state=42, solver='sag',\n",
            "                                                 tol=0.2))],\n",
            "                 voting='soft')\n",
            "F1 Weighted-Score: 0.8977 & Balanced Accuracy: 0.8977\n",
            "Classifier:\n",
            "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
            "                             ('decision_tree',\n",
            "                              LogisticRegression(random_state=42, solver='sag',\n",
            "                                                 tol=0.2))])\n",
            "F1 Weighted-Score: 0.8563 & Balanced Accuracy: 0.8577\n"
          ]
        }
      ],
      "source": [
        "### BEGIN SOLUTION\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import  VotingClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# USE RANDOM STATE!\n",
        "cls1 = KNeighborsClassifier() # Classifier #1\n",
        "cls2 = LogisticRegression(random_state=RANDOM_STATE, solver='sag', tol=0.2) # Classifier #2\n",
        "\n",
        "soft_vcls = VotingClassifier(estimators=[\n",
        "            ('knn', cls1), ('decision_tree', cls2)], voting = 'soft')  # Soft Voting Classifier\n",
        "hard_vcls =  VotingClassifier(estimators=[\n",
        "            ('knn', cls1), ('decision_tree', cls2)], voting = 'hard') # Hard Voting Classifier\n",
        "\n",
        "svlcs_scores = cross_validate(estimator = soft_vcls, X = X, y = y, scoring = ['f1_weighted', 'balanced_accuracy'], cv = 5, n_jobs = -1)\n",
        "s_avg_fmeasure = np.average(svlcs_scores['test_f1_weighted']) # The average f-measure\n",
        "s_avg_accuracy = np.average(svlcs_scores['test_balanced_accuracy']) # The average accuracy\n",
        "\n",
        "hvlcs_scores = cross_validate(estimator = hard_vcls, X = X, y = y, scoring = ['f1_weighted', 'balanced_accuracy'], cv = 5, n_jobs = -1)\n",
        "h_avg_fmeasure = np.average(hvlcs_scores['test_f1_weighted']) # The average f-measure\n",
        "h_avg_accuracy = np.average(hvlcs_scores['test_balanced_accuracy']) # The average accuracy\n",
        "\n",
        "### END SOLUTION\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(soft_vcls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(hard_vcls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92ubbtE8gtHy"
      },
      "source": [
        "For both soft/hard voting classifiers the F1 weighted score should be above 0.74 and 0.79, respectively, and for balanced accuracy 0.74 and 0.80. Remember! This should be the average performance of each fold, as measured through cross-validation with 5 folds!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPG8MdFLXMmV"
      },
      "source": [
        "### 1.2 Randomization\n",
        "\n",
        "You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1_weighted/balanced_accuracy score. The dictionaries should contain four different elements. Use the same cross-validation approach as before!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmkaP-DjXMmV",
        "outputId": "c23213b7-bce2-4fcf-97a4-cfe524d257a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=7,\n",
            "                                                   random_state=42),\n",
            "                  n_jobs=-1, random_state=42)\n",
            "BaggingClassifier(bootstrap_features=True,\n",
            "                  estimator=DecisionTreeClassifier(max_depth=7,\n",
            "                                                   random_state=42),\n",
            "                  max_features=0.5, max_samples=0.7, n_jobs=-1,\n",
            "                  random_state=42)\n",
            "RandomForestClassifier(max_depth=5, n_estimators=10, n_jobs=-1, random_state=42)\n",
            "DecisionTreeClassifier(max_depth=7, random_state=42)\n",
            "Classifier: Simple Decision -  F1 Weighted: 0.7615\n",
            "Classifier: Ensemble with bagging -  F1 Weighted: 0.8184\n",
            "Classifier: Ensemble with random patches -  F1 Weighted: 0.8228\n",
            "Classifier: Ensemble with random forest -  F1 Weighted: 0.7717\n",
            "Classifier: Simple Decision -  BalancedAccuracy: 0.762\n",
            "Classifier: Ensemble with bagging -  BalancedAccuracy: 0.8186\n",
            "Classifier: Ensemble with random patches -  BalancedAccuracy: 0.8228\n",
            "Classifier: Ensemble with random forest -  BalancedAccuracy: 0.7727\n"
          ]
        }
      ],
      "source": [
        "### BEGIN SOLUTION\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "ens1 = BaggingClassifier(estimator = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=7), n_estimators=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "ens2 = BaggingClassifier(estimator = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=7), n_estimators=10, random_state=RANDOM_STATE, n_jobs=-1, bootstrap_features=True, max_samples=0.7, max_features=0.5)\n",
        "ens3 = RandomForestClassifier(max_depth=5, random_state=RANDOM_STATE, n_estimators=10, n_jobs=-1)\n",
        "tree = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth = 7)\n",
        "\n",
        "ens1_scores = cross_validate(estimator=ens1, X=X, y=y, cv=5, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
        "ens2_scores = cross_validate(estimator=ens2, X=X, y=y, cv=5, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
        "ens3_scores = cross_validate(estimator=ens3, X=X, y=y, cv=5, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
        "tree_scores = cross_validate(estimator=tree, X=X, y=y, cv=5, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
        "\n",
        "# Example f_measures = {'Simple Decision':0.8551, 'Ensemble with random ...': 0.92, ...}\n",
        "\n",
        "f_measures = {'Simple Decision':np.average([tree_scores['test_f1_weighted']]),\n",
        "              'Ensemble with bagging':np.average(ens1_scores['test_f1_weighted']),\n",
        "              'Ensemble with random patches':np.average(ens2_scores['test_f1_weighted']),\n",
        "              'Ensemble with random forest':np.average(ens3_scores['test_f1_weighted'])}\n",
        "\n",
        "accuracies = {'Simple Decision':np.average([tree_scores['test_balanced_accuracy']]),\n",
        "              'Ensemble with bagging':np.average(ens1_scores['test_balanced_accuracy']),\n",
        "              'Ensemble with random patches':np.average(ens2_scores['test_balanced_accuracy']),\n",
        "              'Ensemble with random forest':np.average(ens3_scores['test_balanced_accuracy'])}\n",
        "### END SOLUTION\n",
        "\n",
        "print(ens1)\n",
        "print(ens2)\n",
        "print(ens3)\n",
        "print(tree)\n",
        "for name,score in f_measures.items():\n",
        "    print(\"Classifier: {} -  F1 Weighted: {}\".format(name,round(score,4)))\n",
        "for name,score in accuracies.items():\n",
        "    print(\"Classifier: {} -  BalancedAccuracy: {}\".format(name,round(score,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJeuV1FXMmX"
      },
      "source": [
        "### 1.3 Question\n",
        "\n",
        "Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApNEPcWEXMmY"
      },
      "source": [
        " **Answer**: It is true that increasing the number of estimators in a bagging classifier can cause a drastical increase in the training time of a classifier. Such an argument can be intuitively explained by the principle \"the more models to be trained, the more computational power is needed\". In order to avoid translating \"computational power\" into \"training time\", one solution would be to use task parallelism (parallel programming). In specific, a number of estimators (ideally all of them) is trained simultaneously, based on the GPU and multi-threading capacities of the execution machine(s), given that all estimators may or may not be trained on the same machine.\n",
        "\n",
        " Such an approach requires that the machine/hardware specifications of the execution machine can apply multiple execution (estimator training) threads in parallel. When feasible, this is the more effective solution.\n",
        "\n",
        " However, some times we may not be able to attain the required number of threads to reach high parallelism factor. Under these circumstances, there are a few more (compromising) solutions. Working with a subset of the available data could be one of them, in order to decrease the burden (=time) on training each one of the estimators, leading in a decreased overall training time that is required for the ensemble model. Such a result (working with an input data subset) can either be done by feature selection or by keeping a percentage of the available example (or combined). Such an approach is obviously not optimal, yet it can be a compromising solution under some circimstances.\n",
        "\n",
        " Last but not least, we would like to note that increasing the number of estimators does not necessarilyl lead to an improved model performance. In particular, there can be a boundary, after which, increasing the number of estimators may not improve (or even downgrade) the model performance. As a result, we can easily understand that decreasing the training time lies (at some times and under specific requirements) in selecting the appropriate number of estimators.\n",
        "\n",
        "Concerning the boosting classifiers, it can be easily observed that using parallel programming is, unfortunately, not an option. The way the ensemble model is constructed in such approaches requires the sequential construction of the separate estimators. The latter are no more independent with one another, since every next classifier is focused on the errors made by the previous one. The \"data subset\" solution is problematic, too. The nature of the boosting classifiers makes it almost intolerant to wasting information, since we need many examples so that the estimators make false presictions, etc.. Last but not least, picking the appropriate number of estimators can be applied in boosting classifiers, for the exact same reasons analyzed previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgvsCbUGXMmY"
      },
      "source": [
        "## 2.0 Creating the best classifier ##\n",
        "In the second part of this assignment, we will try to train the best classifier, as well as to evaluate it using stratified cross valdiation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6daX2mRXMmZ"
      },
      "source": [
        "### 2.1 Good Performing Ensemble\n",
        "\n",
        "In this part of the assignment you are asked to train a good performing ensemble, that is able to be used in a production environment! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure (weighted) & balanced accuracy, using 10-fold stratified cross validation, of your final classifier. Can you achieve a balanced accuracy over 88%, while keeping the training time low? (Tip 1: You can even use a model from the previous parts, but you are advised to test additional configurations, and ensemble architectures, Tip 2: If you try a lot of models/ensembles/configurations or even grid searches, in your answer leave only the classifier you selected as the best!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00xAQ0HfXMmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4196e33-1f32-4d83-d2ee-7b05809f2e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingClassifier(estimators=[('bagging_logistic',\n",
            "                              BaggingClassifier(estimator=LogisticRegression(random_state=42,\n",
            "                                                                             solver='sag',\n",
            "                                                                             tol=0.05),\n",
            "                                                max_features=0.7,\n",
            "                                                max_samples=0.85,\n",
            "                                                n_estimators=25, n_jobs=6,\n",
            "                                                random_state=42)),\n",
            "                             ('svc', LinearSVC(random_state=42, tol=0.05)),\n",
            "                             ('grad_boosting',\n",
            "                              GradientBoostingClassifier(learning_rate=0.2,\n",
            "                                                         n_estimators=113,\n",
            "                                                         random_state=42)),\n",
            "                             ('mlp',\n",
            "                              MLPClassifier(hidden_layer_sizes=200,\n",
            "                                            random_state=42))])\n",
            "Classifier:\n",
            "VotingClassifier(estimators=[('bagging_logistic',\n",
            "                              BaggingClassifier(estimator=LogisticRegression(random_state=42,\n",
            "                                                                             solver='sag',\n",
            "                                                                             tol=0.05),\n",
            "                                                max_features=0.7,\n",
            "                                                max_samples=0.85,\n",
            "                                                n_estimators=25, n_jobs=6,\n",
            "                                                random_state=42)),\n",
            "                             ('svc', LinearSVC(random_state=42, tol=0.05)),\n",
            "                             ('grad_boosting',\n",
            "                              GradientBoostingClassifier(learning_rate=0.2,\n",
            "                                                         n_estimators=113,\n",
            "                                                         random_state=42)),\n",
            "                             ('mlp',\n",
            "                              MLPClassifier(hidden_layer_sizes=200,\n",
            "                                            random_state=42))])\n",
            "F1 Weighted-Score: 0.8980099095983126 & Balanced Accuracy: 0.898071639898563\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "clf1 = BaggingClassifier(estimator=LogisticRegression(random_state=RANDOM_STATE, solver='sag', tol=0.05), max_features=0.7, max_samples=0.85, n_estimators=25, n_jobs=6, random_state=RANDOM_STATE)\n",
        "clf2 = LinearSVC(tol=0.05, random_state=RANDOM_STATE)\n",
        "clf3 = GradientBoostingClassifier(n_estimators=113, learning_rate = 0.2, verbose = 0, random_state=RANDOM_STATE) # Classifier #2\n",
        "clf4 = MLPClassifier(hidden_layer_sizes = 200, random_state=RANDOM_STATE)\n",
        "\n",
        "best_cls = VotingClassifier([('bagging_logistic', clf1), ('svc', clf2), ('grad_boosting', clf3), ('mlp', clf4)], voting=\"hard\") # Hard voting Classifier.\n",
        "\n",
        "print(best_cls)\n",
        "\n",
        "scores = cross_validate(best_cls, X, y, cv = 10, scoring=[\"f1_weighted\", \"balanced_accuracy\"], n_jobs=-1)\n",
        "best_fmeasure = np.average(scores['test_f1_weighted'])  # Trials gave an average of ~ 0.85.\n",
        "best_accuracy = np.average(scores['test_balanced_accuracy'])  # Trials gave an average of ~ 0.85.\n",
        "\n",
        "#END CODE HERE\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(best_cls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(best_fmeasure, best_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnAp-d2DXMmf"
      },
      "source": [
        "## **Classifier construction process**\n",
        "\n",
        "### For the base models\n",
        "\n",
        "At first, we tried a wide variety of different models, as well as \"bagged\" (ensemble) alterations of them. For each one of these models, we measured their balanced accuracy and f1 scores. Based on these evaluation metrics, we made a selection of three models with the best performance among the others.\n",
        "\n",
        "The next step we took was to fine-tune the level-0 models, using grid search. The fine-tuning process resulted in three models:\n",
        "  - a random forest classifier\n",
        "  - a logistic regression classifier\n",
        "  - a decision tree classifier\n",
        "\n",
        "At first, we tried normal and bagged alterations of all the classifiers (both simple and complex) analyzed in classroom and within this notebook.\n",
        "\n",
        "2. After evaluating these models, we chose some well performing ones and  tried different architectures to combine them\n",
        "\n",
        "3. Then, these were combined in different ways as an ensemble (hard voting, stacking with logistic regression, etc.).\n",
        "4. After that, after reaching a good result (>85% but still a little lower than 1.2, having that as the baseline), I tried slightly different well-performing models as base models and/or tweaking some hyperparameters of present base models (base on the results on their individual tuning) trying to get as good final scores as possible (and of course to get something better than 1.2 results). This is because it was observed that the absolute best performing models and best tuning of individual (base) models of the ensemble didn't necessarily translate to the best ensemble.\n",
        "5. Finally, after already having a good model and not reaching a better one with the tests above, I stick with the best achieved so far.\n",
        "6. In conclusion the model was not too much better than the one in 1.2 but has a (slightly) better Balanced Accuracy and about the same f1 score.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnos1uqzXMma"
      },
      "source": [
        "### 2.2 Question\n",
        " What other ensemble architectures you tried, and why you did not choose them as your final classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dAfbTfXMmb"
      },
      "source": [
        "### **Results of attempted final ensemble classifiers (10 fold cross-validation)**\n",
        "* `StackingClassifier(estimators=[('bagging_logistic', BaggingClassifier(base_estimator=LogisticRegression(random_state=42, solver='sag', tol=0.05), max_features=0.7, max_samples=0.85, n_estimators=25, n_jobs=6, random_state=42)), ('bagging_sgd', BaggingClassifier(base_estimator=SGDClassifier(random_state=42), max_features=0.9, max_samples=0.5, n_estimators=35, n_jobs=4, random_state=42)), ('bagging_mlp', BaggingClassifier(base_estimator=MLPClassifier(hidden_layer_sizes=5, random_state=42), n_estimators=3, n_jobs=1, random_state=42)), ('grad_boosting', GradientBoostingClassifier(learning_rate=0.2, n_estimators=113))], final_estimator=GaussianNB(), n_jobs=1)`\n",
        "\n",
        "  Classifier:\n",
        "\n",
        "  F1 Weighted-Score:0.853 & Balanced Accuracy:0.849\n",
        "\n",
        "\n",
        "* `VotingClassifier(estimators=[('bagging_logistic', BaggingClassifier(base_estimator=LogisticRegression(random_state=42, solver='sag', tol=0.05), max_features=0.7, max_samples=0.85, n_estimators=25, n_jobs=6, random_state=42)), ('svc', LinearSVC(random_state=42, tol=0.05)), ('grad_boosting', GradientBoostingClassifier(learning_rate=0.2, n_estimators=113)), ('mlp', MLPClassifier(hidden_layer_sizes=200, random_state=42))])`\n",
        "\n",
        "  Classifier:\n",
        "\n",
        "  F1 Weighted-Score:0.859 & Balanced Accuracy:0.857\n",
        "\n",
        "* `StackingClassifier(estimators=[('bagging_logistic', BaggingClassifier(base_estimator=LogisticRegression(random_state=42, solver='sag', tol=0.05), max_features=0.7, n_estimators=15, n_jobs=6, random_state=42)), ('mlp', MLPClassifier(hidden_layer_sizes=113, random_state=42))], final_estimator=LogisticRegression(random_state=42), n_jobs=1)`\n",
        "\n",
        "  Classifier:\n",
        "\n",
        "  F1 Weighted-Score:0.856 & Balanced Accuracy:0.850\n",
        "* `StackingClassifier(estimators=[('bagging_logistic', BaggingClassifier(base_estimator=LogisticRegression(random_state=42, solver='sag', tol=0.05), max_features=0.7, n_estimators=15, n_jobs=6, random_state=42)), ('svc', LinearSVC(random_state=42, tol=0.05)), ('grad_boosting', GradientBoostingClassifier(learning_rate=0.25, n_estimators=113)), ('mlp', MLPClassifier(hidden_layer_sizes=113, random_state=42))], final_estimator=GaussianNB(), n_jobs=1)`\n",
        "\n",
        "  Classifier:\n",
        "\n",
        "  F1 Weighted-Score:0.856 & Balanced Accuracy:0.852\n",
        "\n",
        "* `StackingClassifier(estimators=[('bagging_logistic', BaggingClassifier(base_estimator=LogisticRegression(random_state=42, solver='sag', tol=0.05), max_features=0.7, max_samples=0.85, n_estimators=25, n_jobs=6, random_state=42)), ('svc', LinearSVC(random_state=42, tol=0.05)), ('random_forest', RandomForestClassifier(n_estimators=200, n_jobs=6, random_state=42))], final_estimator=GaussianNB(), n_jobs=1)`\n",
        "\n",
        "  Classifier:\n",
        "\n",
        "  F1 Weighted-Score:0.849 & Balanced Accuracy:0.844\n",
        "\n",
        "\n",
        "### Results of the final classifier (10-fold cross-validation)\n",
        "Model: `VotingClassifier(estimators=[('bagging_logistic',BaggingClassifier(base_estimator=LogisticRegression(random_state=42,solver='sag',tol=0.05),max_features=0.7,max_samples=0.85,n_estimators=25,n_jobs=6,random_state=42)),('svc',LinearSVC(random_state=42,tol=0.05)),('grad_boosting',GradientBoostingClassifier(learning_rate=0.2,n_estimators=113,random_state=42)),('mlp',MLPClassifier(hidden_layer_sizes=200,random_state=42))])`\n",
        "\n",
        "\n",
        "\n",
        "Metrics (10-fold stratified cross validation):\n",
        "Classifier:\n",
        "F1 Weighted-Score:0.857 & Balanced Accuracy:0.855"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI1yb95A8r3k"
      },
      "source": [
        "### 2.3 Setup the Final Classifier\n",
        "Finally, in this last cell, set the cls variable to either the best model as occured by the stratified cross_validation, or choose to retrain your classifier in the whole dataset (X, y). There is no correct answer, but try to explain your choice. Then, save your model using pickle and upload it with your submission to e-learning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYNkmiUOXMmh",
        "outputId": "10fa9366-396d-448d-8ba3-1722f68e3d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.998814463544754\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "cls = best_cls.fit(X, y)\n",
        "\n",
        "# save with pickle\n",
        "file_name = \"best_cls_3651.joblib\"\n",
        "pickle.dump(cls, open(file_name, 'wb'))\n",
        "### END SOLUTION\n",
        "\n",
        "\n",
        "# load\n",
        "cls = pickle.load(open(file_name, \"rb\"))\n",
        "\n",
        "predictions = cls.predict(X)\n",
        "print(balanced_accuracy_score(y, predictions))\n",
        "\n",
        "# test_set = pd.read_csv(\"test_set_noclass.csv\")\n",
        "# predictions = cls.predict(test_set)\n",
        "\n",
        "# We are going to run the following code\n",
        "if False:\n",
        "  from sklearn.metrics import f1_score, balanced_accuracy_score\n",
        "  final_test_set = pd.read_csv('test_set.csv')\n",
        "  ground_truth = final_test_set['CLASS']\n",
        "  print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(predictions, ground_truth)))\n",
        "  print(\"F1 Weighted-Score: {}\".format(f1_score(predictions, ground_truth, average='weighted')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pB4bTSj4Bvj"
      },
      "source": [
        "Both metrics should aim above 82%! This is going to be tested by us! Make sure your cross validation or your retrained model achieves high balanced accuracy and f1_score (based on 2.1) (more than 88%) as it should achieve at least 82% in our unknown test set!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vju0hBtbjDME"
      },
      "source": [
        "### Best classifier selection\n",
        "\n",
        "We opted for keeping the"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJK4OGy9J9f"
      },
      "source": [
        "Please provide your feedback regarding this project! Did you enjoy it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVit9HDVTQmf"
      },
      "source": [
        "The project was really interesting and constructive! ML is absolutely the best course in CSD AUTh. Thank you for the quality you offer!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}